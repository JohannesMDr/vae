{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCxS7DXDnNnEqvV5OzeVPp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohannesMDr/vae/blob/master/vae_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAIokwWNI94C",
        "colab_type": "text"
      },
      "source": [
        "# README\n",
        "* ref: https://github.com/hsinyilin19/ResNetVAE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeLdbuRXfGpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuScbqRZsNXu",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKVZRnQqfLXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(data.Dataset):\n",
        "    \"Characterizes a dataset for PyTorch\"\n",
        "    def __init__(self, filenames, labels, transform=None):\n",
        "        \"Initialization\"\n",
        "        self.filenames = filenames\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"Denotes the total number of samples\"\n",
        "        return len(self.filenames)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"Generates one sample of data\"\n",
        "        # Select sample\n",
        "        filename = self.filenames[index]\n",
        "        X = Image.open(filename)\n",
        "\n",
        "        if self.transform:\n",
        "            X = self.transform(X)     # transform\n",
        "\n",
        "        y = torch.LongTensor([self.labels[index]])\n",
        "        return {\n",
        "            'input': inp,\n",
        "            'recon': inp\n",
        "        }\n",
        "    \n",
        "    @classmethod\n",
        "    def show_x(cls, ax, sample):\n",
        "\n",
        "    @classmethod\n",
        "    def show_y(cls, ax, sample):\n",
        "\n",
        "    def show_sample(self, index, show_y=False, figsize=(16,8)):\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-9Onsuirx2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(...):\n",
        "    return Dataset(indices[val_length:]), Dataset(indicies[:val_length])\n",
        "\n",
        "trainset, valset = make_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vLq8IoMsLqm",
        "colab_type": "text"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vnd_NYnfODV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2D_output_size(img_size, padding, kernel_size, stride):\n",
        "    # compute output shape of conv2D\n",
        "    outshape = (np.floor((img_size[0] + 2 * padding[0] - (kernel_size[0] - 1) - 1) / stride[0] + 1).astype(int),\n",
        "                np.floor((img_size[1] + 2 * padding[1] - (kernel_size[1] - 1) - 1) / stride[1] + 1).astype(int))\n",
        "    return outshape\n",
        "\n",
        "def convtrans2D_output_size(img_size, padding, kernel_size, stride):\n",
        "    # compute output shape of conv2D\n",
        "    outshape = ((img_size[0] - 1) * stride[0] - 2 * padding[0] + kernel_size[0],\n",
        "                (img_size[1] - 1) * stride[1] - 2 * padding[1] + kernel_size[1])\n",
        "    return outshape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEHVPsThfTt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet_VAE(nn.Module):\n",
        "    def __init__(self, fc_hidden1=1024, fc_hidden2=768, drop_p=0.3, CNN_embed_dim=256):\n",
        "        super(ResNet_VAE, self).__init__()\n",
        "\n",
        "        self.fc_hidden1, self.fc_hidden2, self.CNN_embed_dim = fc_hidden1, fc_hidden2, CNN_embed_dim\n",
        "\n",
        "        # CNN architechtures\n",
        "        self.ch1, self.ch2, self.ch3, self.ch4 = 16, 32, 64, 128\n",
        "        self.k1, self.k2, self.k3, self.k4 = (5, 5), (3, 3), (3, 3), (3, 3)      # 2d kernal size\n",
        "        self.s1, self.s2, self.s3, self.s4 = (2, 2), (2, 2), (2, 2), (2, 2)      # 2d strides\n",
        "        self.pd1, self.pd2, self.pd3, self.pd4 = (0, 0), (0, 0), (0, 0), (0, 0)  # 2d padding\n",
        "\n",
        "        # encoding components\n",
        "        resnet = models.resnet152(pretrained=True)\n",
        "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
        "        self.resnet = nn.Sequential(*modules)\n",
        "        self.fc1 = nn.Linear(resnet.fc.in_features, self.fc_hidden1)\n",
        "        self.bn1 = nn.BatchNorm1d(self.fc_hidden1, momentum=0.01)\n",
        "        self.fc2 = nn.Linear(self.fc_hidden1, self.fc_hidden2)\n",
        "        self.bn2 = nn.BatchNorm1d(self.fc_hidden2, momentum=0.01)\n",
        "        # Latent vectors mu and sigma\n",
        "        self.fc3_mu = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)      # output = CNN embedding latent variables\n",
        "        self.fc3_logvar = nn.Linear(self.fc_hidden2, self.CNN_embed_dim)  # output = CNN embedding latent variables\n",
        "\n",
        "        # Sampling vector\n",
        "        self.fc4 = nn.Linear(self.CNN_embed_dim, self.fc_hidden2)\n",
        "        self.fc_bn4 = nn.BatchNorm1d(self.fc_hidden2)\n",
        "        self.fc5 = nn.Linear(self.fc_hidden2, 64 * 4 * 4)\n",
        "        self.fc_bn5 = nn.BatchNorm1d(64 * 4 * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Decoder\n",
        "        self.convTrans6 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=self.k4, stride=self.s4,\n",
        "                               padding=self.pd4),\n",
        "            nn.BatchNorm2d(32, momentum=0.01),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.convTrans7 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=32, out_channels=8, kernel_size=self.k3, stride=self.s3,\n",
        "                               padding=self.pd3),\n",
        "            nn.BatchNorm2d(8, momentum=0.01),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.convTrans8 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=8, out_channels=3, kernel_size=self.k2, stride=self.s2,\n",
        "                               padding=self.pd2),\n",
        "            nn.BatchNorm2d(3, momentum=0.01),\n",
        "            nn.Sigmoid()    # y = (y1, y2, y3) \\in [0 ,1]^3\n",
        "        )\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.resnet(x)  # ResNet\n",
        "        x = x.view(x.size(0), -1)  # flatten output of conv\n",
        "\n",
        "        # FC layers\n",
        "        x = self.bn1(self.fc1(x))\n",
        "        x = self.relu(x)\n",
        "        x = self.bn2(self.fc2(x))\n",
        "        x = self.relu(x)\n",
        "        # x = F.dropout(x, p=self.drop_p, training=self.training)\n",
        "        mu, logvar = self.fc3_mu(x), self.fc3_logvar(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = Variable(std.data.new(std.size()).normal_())\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = self.relu(self.fc_bn4(self.fc4(z)))\n",
        "        x = self.relu(self.fc_bn5(self.fc5(x))).view(-1, 64, 4, 4)\n",
        "        x = self.convTrans6(x)\n",
        "        x = self.convTrans7(x)\n",
        "        x = self.convTrans8(x)\n",
        "        x = F.interpolate(x, size=(224, 224), mode='bilinear')\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_reconst = self.decode(z)\n",
        "\n",
        "        return {\n",
        "            'recon': x_reconst,\n",
        "            'z': z,\n",
        "            'mu': mu,\n",
        "            'logvar': logvar\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZaxlFv7sUoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KL_div(mu, logvar):\n",
        "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "class Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.crit_bce = F.binary_cross_entropy()\n",
        "        self.crit_kld = KL_div\n",
        "    def forward(self, pred, batch):\n",
        "        loss = {}\n",
        "        loss['bce'] = self.crit_bce(pred['recon'], batch['recon'], reduction='sum')\n",
        "        loss['kld'] = self.crit_kld(pred['mu'], pred['logvar'])\n",
        "        loss_all = loss['bce'] + loss['kld']\n",
        "        return loss_all, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSAJgKHbscf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, opt, train_ld, val_ld, loss_fn=Loss(), device='cuda'):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.opt = opt\n",
        "        self.train_ld = train_ld\n",
        "        self.val_ld = val_ld\n",
        "        self.device = device\n",
        "\n",
        "    def epoch(self, pbar, training=True):\n",
        "        n_samples = 0\n",
        "        stat_log = defaultdice(float)\n",
        "        loss_log = 0\n",
        "        for batch in pbar:\n",
        "            bs = batch['input'].size(0)\n",
        "            n_samples += bs\n",
        "            for k in batch:\n",
        "                batch[k] = F.pad(batch[k].to(self.device), (0,1))\n",
        "            x = F.pad(batch['input'], (0,3))\n",
        "            y = self.model(x)\n",
        "            loss, stat = self.loss_fn(y, batch)\n",
        "            if training:\n",
        "                self.opt.zero_grad()\n",
        "                loss.backward()\n",
        "                self.opt.step()\n",
        "            \n",
        "            loss = loss.detach().cpu().numpy()\n",
        "            loss_log += loss\n",
        "            for k in stat:\n",
        "                stat_log[k] += stat[k].detach().cpu().numpy()\n",
        "            pbar.comment = '{:.4f}'.format(loss)\n",
        "        for k in stat:\n",
        "            stat_log[k] /= n_samples\n",
        "        loss_log /= n_samples\n",
        "        return loss_log, stat_log\n",
        "\n",
        "    def train(self, mb):\n",
        "        self.model.train()\n",
        "        pbar = progress_bar(self.train_ld, parent=mb)\n",
        "        return self.epoch(pbar, training=True)\n",
        "\n",
        "    def val(self, mb):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            pbar = progress_bar(self.val_ld, parent=mb)\n",
        "            return self.epoch(pbar, training=False)\n",
        "\n",
        "    def show_results(self, num=3, figsize=(8,8)):\n",
        "        fig, ax = plt.subplots(num, 2, figsize=figsize)\n",
        "        if num == 1:\n",
        "            ax = ax.reshape(1,-1)\n",
        "        self.model.eval()\n",
        "        show_x = self.val_ld.dataset.show_x\n",
        "        show_y = self.val_ld.dataset.show_y\n",
        "        n = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_ld:\n",
        "                bs = batch['input'].size(0)\n",
        "                for k in batch:\n",
        "                    batch[k] = F.pad(batch[k].to(self.device), (0,1))\n",
        "                x = F.pad(batch['input'], (0,3))\n",
        "                y = self.model(x)\n",
        "                for b in range(bs):\n",
        "                    sample_inp = {'input': batch['input'][b]}\n",
        "                    sample_pred = {k:v[b] for k,v in y.items()}\n",
        "                    sample_batch = {k:v[b] for k,v in batch.items()}\n",
        "                    ax[n,0].set_title(\"pred\")\n",
        "                    show_x(ax[n,0], sample_inp)\n",
        "                    show_y(ax[n,0], sample_pred)\n",
        "                    ax[n,1].set_title(\"actual\")\n",
        "                    show_x(ax[n,1], sample_inp)\n",
        "                    show_y(ax[n,1], sample_batch)\n",
        "                    n += 1\n",
        "                    if n >= num:\n",
        "                        break\n",
        "                if n >= num:\n",
        "                    break\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1qvh3eyx6_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VAE(///)\n",
        "trainset, valset = make_dataset()\n",
        "trainloader = data.DataLoader(trainset, batch_size=8, shuffle=True, drop_last=True)\n",
        "valloader = data.DataLoader(valset, batch_size=8, shuffle=False)\n",
        "\n",
        "# freeze\n",
        "train_bn = True\n",
        "flat_backbone = flatten_model(model.backbone)\n",
        "for layer in flat_backbone:\n",
        "    if train_bn and isinstance(layer, bn_types): continue\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "optimizer = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    base_lr,\n",
        "    weight_decay=1e-3)\n",
        "\n",
        "trainer = Trainer(model, optimizer, trainloader, valloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAv2nHh_y6uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.show_results(3, figsize=(12,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfFp9p1uzBwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 40\n",
        "drop = [10]\n",
        "mb = master_bar(range(1, epoch+1))\n",
        "mb.names = ['train', 'val']\n",
        "\n",
        "tloss_list = []\n",
        "vloss_lis = []\n",
        "best_vloss = None\n",
        "for e in mb:\n",
        "    tloss, stat = trainer.train(mb)\n",
        "    tloss_list.append(tloss)\n",
        "    stat_str = \"\"\n",
        "    for k in stat:\n",
        "        stat_str += \", {}:{:.3e}\".format(k, stat[k])\n",
        "    mb.write(\"train {}, loss {:.4f}\".format(e, tloss) + stat_str)\n",
        "    vloss, stat = trainer.val(mb)\n",
        "    vloss_list.append(vloss)\n",
        "    stat_str = \"\"\n",
        "    for k in stat:\n",
        "        stat_str += \", {}:{:.3e}\".format(k, stat[k])\n",
        "    mb.write(\"val {}, loss {:.4f}\".format(e, tloss) + stat_str)\n",
        "    if (best_vloss is None) or (best_vloss > vloss):\n",
        "        best_vloss = vloss\n",
        "        torch.save(model.state_dict(), \"~~/best_model\")\n",
        "    if e in drop:\n",
        "        lr = base_lr * (0.2 ** (drop.index(e)+1))\n",
        "        mb.write('Drop LR to {}'.format(lr))\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4KvDz1U0x7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.arange(1,epoch+1), tloss_list, label=\"train\")\n",
        "plt.plot(np.arange(1,epoch+1), vloss_list, label=\"val\")\n",
        "plt.legend()\n",
        "plt.savefig(path_model + '/history.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvLGRU4U1APJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.show_results(3, figsize=(12,8))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}